{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U96d3HOdJ9f_"
      },
      "outputs": [],
      "source": [
        "#Example of supress warnings for Numpy version out of range (optional)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)\n",
        "\n",
        "#Some recommended libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "#Some recommended libraries for the text processing tasks\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "\n",
        "import pickle\n",
        "\n",
        "from dask import dataframe as dd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 100)"
      ],
      "metadata": {
        "id": "Bq3z--9JcmI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cards = pd.read_csv('sd254_cards.csv')"
      ],
      "metadata": {
        "id": "l1M96y6AKTHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans = pd.read_csv('credit_card_transactions-ibm_v2.csv').iloc[:20000,:]"
      ],
      "metadata": {
        "id": "DHDIWsk0f3oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_trans.head()"
      ],
      "metadata": {
        "id": "R_NThet9jdJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop potentially sensitive and unhelpful features\n",
        "df_cards.drop(columns=['Card Number', 'CVV', 'Expires'], inplace=True)\n",
        "\n",
        "# encode categorical features, format numerical\n",
        "df_cards_encoded = pd.get_dummies(df_cards, columns=['Card Type', 'Card Brand'])\n",
        "df_cards_encoded['Has Chip'] = df_cards_encoded['Has Chip'].apply(lambda x: 1 if x.lower() == 'yes' else 0)\n",
        "df_cards_encoded['Card on Dark Web'] = df_cards_encoded['Card on Dark Web'].apply(lambda x: 1 if x.lower() == 'yes' else 0)\n",
        "df_cards_encoded['Credit Limit'] = df_cards_encoded['Credit Limit'].str.replace('$', '').astype(float)\n",
        "\n",
        "# handle date columns\n",
        "df_cards_encoded['Acct Open Date'] = pd.to_datetime(df_cards_encoded['Acct Open Date'])\n",
        "df_cards_encoded['Year'] = df_cards_encoded['Acct Open Date'].dt.year\n",
        "df_cards_encoded['Month'] = df_cards_encoded['Acct Open Date'].dt.month\n",
        "df_cards_encoded['Day'] = df_cards_encoded['Acct Open Date'].dt.day\n",
        "df_cards_encoded['Acct Age (Years)'] = 2019 - df_cards_encoded['Acct Open Date'].dt.day / 365\n",
        "df_cards_encoded.drop(columns='Acct Open Date', inplace=True)\n",
        "\n",
        "df_cards_encoded['Years Since PIN Last Changed'] = 2019 - df_cards_encoded['Year PIN last Changed']\n",
        "\n",
        "# scale features\n",
        "scaler = StandardScaler()\n",
        "df_cards_encoded[['Credit Limit', 'Years Since PIN Last Changed']] = scaler.fit_transform(df_cards_encoded[['Credit Limit', 'Years Since PIN Last Changed']])\n",
        "\n",
        "# create ID column\n",
        "df_cards_encoded['ID'] = df_cards_encoded['User'] + df_cards_encoded['CARD INDEX']\n",
        "\n",
        "# detect outliers\n",
        "# plot = sns.scatterplot(x='Credit Limit', y='Cards Issued', data=df_cards_encoded)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "cyPcGUdzOtlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_cards_encoded"
      ],
      "metadata": {
        "id": "9g4cBFXaApfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans_encoded = df_trans.copy()\n",
        "# drop merchant name field\n",
        "df_trans_encoded = df_trans_encoded.drop(columns='Merchant Name')\n",
        "# fill NaN with 'None'\n",
        "df_trans_encoded = df_trans_encoded.fillna('None')\n",
        "# select the first million rows"
      ],
      "metadata": {
        "id": "Q6UXrcWMSYZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_trans_encoded.head()"
      ],
      "metadata": {
        "id": "wgnd64qtrDNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical values\n",
        "df_trans_encoded = pd.get_dummies(df_trans_encoded, columns=['Use Chip', 'Merchant City', 'Merchant State', 'Errors?'])"
      ],
      "metadata": {
        "id": "1NLgzNTzkSie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans_encoded['Amount'] = df_trans_encoded['Amount'].str.replace('$', '').astype(float)\n",
        "df_trans_encoded['Time'] = pd.to_datetime(df_trans_encoded['Time'])\n",
        "df_trans_encoded['Time'] = df_trans_encoded['Time'].dt.hour+df_trans_encoded['Time'].dt.minute/60\n"
      ],
      "metadata": {
        "id": "xLYE0htAs07I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans_encoded['ID'] = df_trans_encoded['User'] + df_trans_encoded['Card']"
      ],
      "metadata": {
        "id": "5qFqW26hAyXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans_encoded['Is Fraud?'] = df_trans_encoded['Is Fraud?'].apply(lambda x: 1 if x.lower() == 'yes' else 0)"
      ],
      "metadata": {
        "id": "ZyBY5NI6t3v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df_trans_encoded[['Amount', 'Time']] = scaler.fit_transform(df_trans_encoded[['Amount', 'Time']])"
      ],
      "metadata": {
        "id": "uKVctCA87sE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans_encoded.replace('None', 0, inplace=True)"
      ],
      "metadata": {
        "id": "J7wRQKq23BII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ddf_trans_encoded = dd.from_pandas(df_trans_encoded, npartitions=4)\n",
        "# ddf_cards = dd.from_pandas(df_cards, npartitions=4)\n",
        "\n",
        "# ddf_all = ddf_trans_encoded.join(ddf_cards.set_index('CARD INDEX'), on='Card', lsuffix='_trans', rsuffix='_card')\n",
        "\n",
        "# df_all = ddf_all.compute()\n",
        "df_all = df_trans_encoded.merge(df_cards_encoded, on='ID')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mM4rn14mt-RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # print(df_all[df_all['Cards Issued'] > 1]['Is Fraud?'].value_counts())\n",
        "# # print(df_all[df_all['Cards Issued'] == 1]['Is Fraud?'].value_counts())\n",
        "\n",
        "# plt.scatter(df_all['Amount'], df_all['Is Fraud?'])\n",
        "# plt.xlabel('Amount')\n",
        "# plt.ylabel('Is Fraud?')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# plt.scatter(df_all['Years Since PIN Last Changed'], df_all['Is Fraud?'])\n",
        "# plt.xlabel('Years Since PIN Last Changed')\n",
        "# plt.ylabel('Is Fraud?')\n",
        "# plt.show()\n",
        "\n",
        "# # for year in range(1,16):\n",
        "# #     print(year)\n",
        "# #     print(df_all[df_all['Years Since PIN Last Changed'] == year]['Is Fraud?'].value_counts())\n",
        "\n",
        "# result = pd.crosstab(df_all['Years Since PIN Last Changed'], df_all['Is Fraud?'])\n",
        "# result = result.rename(columns={0: 'Not Fraud', 1: 'Is Fraud'})\n",
        "# result['Percent Fraud'] = result['Is Fraud']/result.sum(axis=1)*100\n",
        "# print(result)\n",
        "# plt.scatter(df_all['Acct Age (Years)'], df_all['Is Fraud?'])\n",
        "# plt.xlabel('Account Age (Years)')\n",
        "# plt.ylabel('Is Fraud?')\n",
        "# plt.show\n",
        "\n",
        "# greater_than_15 = pd.crosstab(df_all['Acct Age (Years)'] >= 15, df_all['Is Fraud?']);\n",
        "# greater_than_15 = greater_than_15.rename(columns={0: 'Not Fraud', 1: 'Is Fraud'})\n",
        "# greater_than_15['Percent Fraud'] = greater_than_15['Is Fraud']/len(df_all.index)*100\n",
        "# print(greater_than_15)\n",
        "\n",
        "# less_than_15 = pd.crosstab(df_all['Acct Age (Years)'] < 15, df_all['Is Fraud?']);\n",
        "# less_than_15 = less_than_15.rename(columns={0: 'Not Fraud', 1: 'Is Fraud'})\n",
        "# less_than_15['Percent Fraud'] = less_than_15['Is Fraud']/len(df_all.index)*100\n",
        "# print(less_than_15)"
      ],
      "metadata": {
        "id": "MGa6k6ZP7Tmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plt.matshow(df_all.corr())\n",
        "# # plt.show()\n",
        "# # cb = plt.colorbar()\n",
        "# # cb.ax.tick_params(labelsize=14)\n",
        "# # plt.title('Correlation Matrix', fontsize=16);\n",
        "\n",
        "# corrlation = df_all.corrwith(df_all['Is Fraud?'])\n",
        "# corrlation.sort_values(ascending=False, inplace=True)\n",
        "# print(corrlation)\n"
      ],
      "metadata": {
        "id": "JQNio99fQuK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "df_pca = pca.fit_transform(df_all)"
      ],
      "metadata": {
        "id": "D1N26vvBjACh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_pca, df_all['Is Fraud?'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "H3_JLpkM375h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters = {'C': np.logspace(-3,3,7), 'penalty': [\"l1\",\"l2\"]}\n",
        "\n",
        "# model = GridSearchCV(LogisticRegression(), parameters, verbose=3, cv=2)\n",
        "\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# print(model.best_params_)\n",
        "\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "O_KnfITLmAzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(model, open('logreg_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "LnVawXgSK6CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# param_grid = {\n",
        "#     'C': [0.001, 0.01, 0.1, 1],\n",
        "#     'kernel': ['linear', 'rbf'],\n",
        "#     'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "#     'class_weight': ['balanced', None]\n",
        "# }\n",
        "\n",
        "# svm = RandomizedSearchCV(SVC(), param_grid, verbose=3, cv=2)\n",
        "# svm.fit(X_train, y_train)\n",
        "\n",
        "# print(svm.best_params_)\n",
        "\n",
        "# y_pred = svm.predict(X_test)\n",
        "\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "L8pHjw7Fmkbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(svm, open('svm_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "VgxTRkyFLH7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_cv = pickle.load(open('svm_model.pkl', 'rb'))\n",
        "best_params = svm_cv.best_params_\n",
        "print(best_params)\n",
        "svm = svm_cv.best_estimator_"
      ],
      "metadata": {
        "id": "iP9RjjMyC86f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm.feature_names = df_all.columns"
      ],
      "metadata": {
        "id": "s0cmdw2Ka5OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "precision = metrics.average_precision_score(y_test, y_pred)\n",
        "f1 = metrics.f1_score(y_test, y_pred)\n",
        "recall = metrics.recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "feature_coefficients = svm.coef_[0]\n",
        "print(svm.feature_names[feature_coefficients.tolist().index(max(feature_coefficients))])\n",
        "print((max(feature_coefficients)))\n",
        "for i in range(len(df_all.columns)):\n",
        "  if feature_coefficients[i] >= 0.001 or feature_coefficients[i] <= -0.001:\n",
        "    print(f\"{svm.feature_names[i]}: {feature_coefficients[i]}\")\n",
        "\n",
        "sns.heatmap(df_all.corr(), annot=True)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "ncaqQClRGwob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}